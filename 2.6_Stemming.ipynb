{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Stemming\n",
    "\n",
    "The next step in preprocessing is to standardise the text. One option for this is stemming, where words are reduced to their base form. For example, words like ‘connecting’ or ‘connected’ will be stemmed to the base form ‘connect’. Stemming works by removing suffix/ending of word but can sometimes lead to the base form not being meaningful or a proper word.\n",
    "\n",
    "We standardize the text in this way because it will lower the number of unique words in our dataset; therefore reducing the size and complexity of our data. Removing complexity and noise from the data is an important step for preparing our data properly for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_tokens = ['connecting', 'connected', 'connectivity', 'connect', 'connects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting  :  connect\n",
      "connected  :  connect\n",
      "connectivity  :  connect\n",
      "connect  :  connect\n",
      "connects  :  connect\n"
     ]
    }
   ],
   "source": [
    "for t in connect_tokens:\n",
    "    print(t, \" : \", ps.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_tokens = ['learned', 'learning', 'learn', 'learns', 'learner', 'learners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned  :  learn\n",
      "learning  :  learn\n",
      "learn  :  learn\n",
      "learns  :  learn\n",
      "learner  :  learner\n",
      "learners  :  learner\n"
     ]
    }
   ],
   "source": [
    "# observe how different forms reduce to the root\n",
    "for t in learn_tokens:\n",
    "    print(t, \" : \", ps.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_tokens = ['likes', 'better', 'worse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes  :  like\n",
      "better  :  better\n",
      "worse  :  wors\n"
     ]
    }
   ],
   "source": [
    "for t in likes_tokens:\n",
    "    print(t, \" : \", ps.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  :  run\n",
      "runner  :  runner\n",
      "ran  :  ran\n",
      "runs  :  run\n"
     ]
    }
   ],
   "source": [
    "run_tokens = ['running', 'runner', 'ran', 'runs']\n",
    "for t in run_tokens:\n",
    "    print(t, \" : \", ps.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PorterStemmer **reduces words to their root form** (not always linguistically correct)\n",
    "\n",
    "- It's rule-based, so it may return non-standard stems (connectivity → connectiv)\n",
    "\n",
    "- It does not handle irregular forms well (ran → ran, better → better)\n",
    "\n",
    "- Good for feature reduction in classic NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
