{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad080636",
   "metadata": {},
   "source": [
    "# 2.3 Stopwords\n",
    "\n",
    "In this lesson we'll be using the nltk package to remove stop words from text.\n",
    "\n",
    "Stop words are common words in the language which don't carry much meaning e.g. \"and\", \"of\", \"a\", \"to\". \n",
    "\n",
    "We remove these words because it removes a lot of complexity from the data. These words don't add much meaning to text so by removing them we are left with a smaller, cleaner dataset. Smaller, cleaner datasets often lead to increased accuracy in machine learning and will also speed up processing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17742df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767d52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves all English stopwords into a variable\n",
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb7df8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "# Print the list of stop words to see what we will be removing\n",
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "217c64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"it was too far to go to the shop and he did not want her to walk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff01559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far go shop want walk\n"
     ]
    }
   ],
   "source": [
    "# Filter out stopwords from the sentence\n",
    "sentence_no_stopwords = ' '.join([word for word in sentence.split() if word not in (en_stopwords)])\n",
    "print(sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f52b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words from list\n",
    "en_stopwords.remove(\"did\")\n",
    "en_stopwords.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c422dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom stop words\n",
    "en_stopwords.append(\"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc671719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far shop did not want walk\n"
     ]
    }
   ],
   "source": [
    "# Filter the sentence again\n",
    "sentence_no_stopwords_custom = ' '.join([word for word in sentence.split() if word not in (en_stopwords)])\n",
    "print(sentence_no_stopwords_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baac4da",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758f6efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: \n",
      "didn't go school sick tired\n"
     ]
    }
   ],
   "source": [
    "my_sentence = \"She didn't go to school because she felt sick and tired\"\n",
    "my_sentence = my_sentence.lower()\n",
    "\n",
    "my_stopwords = stopwords.words('english')\n",
    "my_stopwords.remove(\"didn't\")\n",
    "my_stopwords.append(\"felt\")\n",
    "\n",
    "cleaned = ' '.join([word for word in my_sentence.split() if word not in my_stopwords])\n",
    "print(\"Cleaned: \")\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f8518",
   "metadata": {},
   "source": [
    "## What I Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc1389",
   "metadata": {},
   "source": [
    "- **Stopwords are commonly used to remove non-informative words from text data.**\n",
    "\n",
    "- You can customize stopword lists by **removing or adding** items for task-specific filtering.\n",
    "\n",
    "- Be careful with negations like \"not\" or \"didn't\" â€” removing them might hurt tasks like sentiment analysis.\n",
    "\n",
    "- Using split() and list comprehensions is a simple way to filter stopwords from text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
